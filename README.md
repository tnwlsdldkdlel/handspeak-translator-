# HandSpeak Translator

한국 수어(KSL) 실시간 인식 및 텍스트 변환 웹 애플리케이션

## 프로젝트 개요

웹캠을 통해 특정 한국 수어(KSL) 제스처(숫자 1~5)를 인식하고, 이를 실시간으로 한국어 텍스트로 변환하는 데모 웹 애플리케이션입니다.

## 기술 스택

- **Frontend**: React + TypeScript + Vite
- **ML Inference**: TensorFlow.js
- **Pre-processing**: MediaPipe Hand Landmarks
- **Model**: Custom MLP Model (KSL 숫자 1~5 분류)

## 시작하기

### 설치

```bash
npm install
```

### 개발 서버 실행

```bash
npm run dev
```

### 빌드

```bash
npm run build
```

### 미리보기

```bash
npm run preview
```

## 프로젝트 구조

```
src/
├── components/     # React 컴포넌트
├── hooks/          # Custom React Hooks
├── utils/          # 유틸리티 함수 및 상수
├── types/          # TypeScript 타입 정의
├── models/         # TensorFlow.js 모델 파일
├── App.tsx         # 메인 앱 컴포넌트
├── main.tsx        # 진입점
└── index.css       # 전역 스타일
```

## 주요 기능

- 실시간 웹캠 제스처 인식
- 한국 수어 숫자 1~5 인식
- 안정화 로직을 통한 오인식 방지
- Undo, Reset, Copy 기능

## 성능 목표

- **FPS**: ≥ 20 FPS
- **추론 지연**: ≤ 30ms
- **인식 정확도**: ≥ 90%

## 사용 방법

1. 개발 서버 실행 후 브라우저에서 앱 접속
   - `npm run dev` 실행
   - 터미널에 표시된 로컬 주소(예: `http://localhost:5173`)로 접속
2. 브라우저에서 **카메라 권한 허용**
3. 화면 구성
   - 왼쪽: 웹캠 영상 + 손 랜드마크 오버레이(토글 가능)
   - 오른쪽: 인식된 숫자 텍스트, Undo / Reset / Copy 버튼
   - 하단 배지: 스트림/모델 상태, FPS, 추론 지연(ms)
4. 제스처 인식
   - KSL 숫자 1~5 제스처를 카메라 중앙에 맞춰서 보여줍니다.
   - 충분한 조명과 단색 배경에서 인식률이 더 좋습니다.
   - 제스처가 안정적으로 유지되면 오른쪽 패널에 `일 이 삼 사 오` 텍스트가 순서대로 쌓입니다.
5. 컨트롤 버튼
   - **Undo**: 마지막 인식 결과만 되돌립니다.
   - **Reset**: 모든 인식 결과를 초기화합니다.
   - **Copy**: 현재 텍스트를 클립보드에 복사합니다.

## 제한 사항

- 현재 모델은 **KSL 숫자 1~5**만 인식하도록 학습되었습니다.
- 학습 데이터가 제한적이므로, 조명/배경/손 크기/카메라 품질에 따라 인식률이 달라질 수 있습니다.
- 주로 **한 손**(오른손 기준)을 사용하는 시나리오를 상정하고 있습니다.
- 브라우저/디바이스 성능에 따라 FPS와 추론 지연이 목표에 미치지 못할 수 있습니다.
- 모든 추론은 **로컬 브라우저**에서 수행되며, 제스처 데이터는 서버로 전송되지 않습니다.

## 참고 문서

자세한 내용은 [PRD 문서](./docs/prd.md)를 참고하세요.

자세한 내용은 [PRD 문서](./docs/prd.md)를 참고하세요.

